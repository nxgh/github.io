- raycaster
- 坐标系

[manual-picking](https://threejs.org/manual/#zh/picking)
[Raycaster-doc](https://threejs.org/docs/index.html?q=raycaster#api/zh/core/Raycaster)

<CH.Scrollycoding preset="https://codesandbox.io/s/7wt1zq">
# 鼠标交互: raycaster

浏览器是一个 2D 视口, 而在里面显示 Three.js 的内容是 3D 场景, 所以，现在就有了一个问题：如何判断用户点击或触碰了哪个对象
, 或者说**如何将 2d 视口的 x 和 y 坐标转换成 three.js 场景中的 3d 坐标**

在 three.js 中常用方式是射线追踪法(raycasting), 在三维空间中计算出鼠标移过了什么物体

其基本原理是：从鼠标处发射一条射线，穿透场景的视椎体，通过计算，找出视锥体中哪些对象与射线相交。

THREE.js 提供了 RayCaster 类来做这些事情。现在我们来创建一个场景，场景中存在三个球体和一条自 (-3, 0, 0) 射向 (1, 0, 0)
的射线，三个球体经过这条射线时会改变颜色

首先我们来搭建基础的场景

```js src/index.js
// from ../../three-demo/three/raycaster/s1.js
```

---

<CH.Section>

接下来我们创建一个 raycaster，和光线投射的原点向量 `rayOrigin`, 为光线提供方向的标准化方向向量 `rayDirOrigin`

- `normalize()` 将该向量转换为单位向量（unit vector）， 也就是说，将该向量的方向设置为和原向量相同，但是其长度（length）
  为 1

- `raycaster.set(rayOrigin, rayDirOrigin)` 使用一个新的原点和方向来更新射线

```js
const raycaster = new THREE.Raycaster()
const rayOrigin = new THREE.Vector3(-3, 0, 0)
const rayDirOrigin = new THREE.Vector3(1, 0, 0)
rayDirOrigin.normalize()
raycaster.set(rayOrigin, rayDirOrigin)
```

</CH.Section>

```js src/index.js
// from .../../three-demo/three/raycaster/s2.js
```

---

<CH.Section>

为了更直观的查看，我们添加一条 line 来表示 raycaster。并且使用 requestAnimationFrame 让三个球体动起来

```js
const line = new THREE.Line(
  new THREE.BufferGeometry().setFromPoints([rayOrigin, new THREE.Vector3(3, 0, 0)]),
  new THREE.LineBasicMaterial({ color: 0x00ff00 })
)
scene.add(line)
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s3.js
```

---

现在我们来实现最终的效果

<CH.Section>

`raycaster.intersectObjects` 检测所有在射线与物体之间，包括或不包括后代的相交部分。

返回结果时，相交部分将按距离进行排序，最近的位于第一个

```js
const intersects = raycaster.intersectObjects(objects)
```

</CH.Section>

<CH.Section>

判断球体对象是否与射线相交

```js
objects.forEach((item) => item.material.color.set('#ff0000'))
intersects.forEach((item) => item.object.material.color.set('#00ff00'))
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s4.js
```

---

## 鼠标拾取物体

在这个案例中，我们监听 `pointerdown` 事件并为其绑定一个方法, 在触发点击事件时,

<CH.Section>
首先会将[屏幕坐标转换为世界坐标](./axes)

```js
pointer.x = (event.clientX / window.innerWidth) * 2 - 1
pointer.y = -(event.clientY / window.innerHeight) * 2 + 1
```

</CH.Section>

`raycaster.setFromCamera(coords , camera)` 与 `raycaster.set` 类似，参数变为

- coords —— 在标准化设备坐标中鼠标的二维坐标 X,Y 分量应当在-1 到 1 之间。
- camera —— 射线所来源的摄像机。

再使用 `intersectObjects` 检测与射线相交的物体, 并使之更改为一个随机颜色(生成颜色时会出现 5 位的 16 进制颜色)

```js src/index.js
// from ../../three-demo/three/raycaster/s5.js
```

---

## 基于 GPU 的拾取

raycaster 看起来效果不错，而且能处理很多用户场景，但是也存在几个问题

- 检查对象是否与射线相交是基于 CPU 运算, 当存在大量对象时，cpu 负载会很高
- 无法检测透明的对象

在这个案例中有四个立方体，且每个立方体应用了一个中心透明的纹理。我们无法透过透明的部分来选中物体

这时，我们需要使用 GPU 拾取

```js src/index.js
// from ../../three-demo/three/raycaster/s6.js
```

---

GPU 拾取的一般做法是给每个 mesh 一种颜色 然后渲染绘制一遍，在鼠标点所在的位置调用 readPixel 读取像素颜色，根据颜色与模型
的对应关系，反推当前拾取到的颜色对应的 mesh

要在 THREE.js 中实现这种拾取方式，需要创建两个场景。一个使用正常的网格对象填充。另外一个使用“拾取材质”的网格对象填充

<CH.Section>

```js
const pickingScene = new THREE.Scene()
pickingScene.background = new THREE.Color(0)
```

</CH.Section>

然后，对于在主场景中的每一个立方体，在 pickingScene 中，在同样的位置，创建一个与原立方体相似的，相关联的“可拾取立方体”，
用对象的 id 生成颜色值，去设置对象的材质。

pickingCube 的一些属性

- 使用 `MeshPhongMaterial` 创建材质
- 材质属性 `emissive` 材质的放射（光）颜色设置为 id
- 材质属性 `color` 和 `specular`: 颜色和高光颜色设置为 0
- 材质属性 `alphaTest` 属性为 0.5 只渲染纹理的 alpha 值大于该属性值的部分
- 材质属性 `blending` 设置为 `NoBlending`，这样 alpha 通道不会作用到 id 生成色

<CH.Section>

```js
function createPickingCube(id, cube) {
  const pickingMaterial = new THREE.MeshPhongMaterial({
    emissive: new THREE.Color(id), // 使用id生成颜色
    color: new THREE.Color(0, 0, 0),
    specular: new THREE.Color(0, 0, 0),
    map: texture,
    transparent: true,
    side: THREE.DoubleSide,
    alphaTest: 0.5,
    blending: THREE.NoBlending,
  })
  const pickingCube = new THREE.Mesh(geometry, pickingMaterial)
  pickingScene.add(pickingCube)
  pickingCube.position.copy(cube.position)
  pickingCube.rotation.copy(cube.rotation)
  pickingCube.scale.copy(cube.scale)
}
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s7.js
```

---

由于我们使用的是像素点拾取，需要将坐标转换更改为

<CH.Section>

```diff
- pointer.x = (event.clientX / window.innerWidth) * 2 - 1
- pointer.y = -(event.clientY / window.innerHeight) * 2 + 1
+ pointer.x = event.clientX
+ pointer.y = event.clientY
```

</CH.Section>

接下来修改 `pointerdown` 事件

首先创建一个 `WebGLRenderTarget` 这里将渲染目标设置为 1x1,

<CH.Section>

```js
const pickingTexture = new THREE.WebGLRenderTarget(1, 1)
// 创建一个 buffer 容器, 用于存储颜色信息
const pixelBuffer = new Uint8Array(4)
```

</CH.Section>

设置相机为鼠标点的一个像素

<CH.Section>

```js
const pixelRatio = renderer.getPixelRatio()
const { drawingBufferWidth, drawingBufferHeight } = renderer.getContext()
const [rectX, rectY] = [(pointer.x * pixelRatio) | 0, (pointer.y * pixelRatio) | 0]
camera.setViewOffset(drawingBufferWidth, drawingBufferHeight, rectX, rectY, 1, 1)
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s8.js
```

---

<CH.Section>

设置当前渲染目标对象并渲染当前场景

```js
renderer.setRenderTarget(pickingTexture)
renderer.render(pickingScene, camera)
renderer.setRenderTarget(null)
```

</CH.Section>

<CH.Section>

清理视野偏移，回归正常, 读取像素信息到 buffer 容器

```js
camera.clearViewOffset()
renderer.readRenderTargetPixels(pickingTexture, 0, 0, 1, 1, pixelBuffer)
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s9.js
```

---

<CH.Section>

获取颜色对应的 id, 这里是为了将 RGB 的数据转为数字

```js
const id = (pixelBuffer[0] << 16) | (pixelBuffer[1] << 8) | pixelBuffer[2]
const intersectedObject = idToObject[id]
```

</CH.Section>

```js src/index.js
// from ../../three-demo/three/raycaster/s10.js
```

</CH.Scrollycoding>
